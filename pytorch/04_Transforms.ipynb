{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2cefe5-e036-4851-91b9-82a12520e492",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "数据并不总是以训练机器学习算法所需的最终处理形式出现。使用 Transforms 来对数据执行一些操作并使其适合训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc28f1ec-8225-4149-bad5-a0c0eb2fd565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "# 所有 TorchVision 数据集都有两个参数\n",
    "#   用于修改特征的 transform\n",
    "#   用于修改标签的 target_transform - 接受包含转换逻辑的可调用对象。\n",
    "\n",
    "\n",
    "# FashionMNIST特征采用PIL图像格式，标签为整数。\n",
    "# 对于训练，我们需要将特征作为归一化张量，将标签作为单热编码张量。为了进行这些转换，我们使用ToTensor和Lambda\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322306d4-d924-4729-8cd5-fb512452a29c",
   "metadata": {},
   "source": [
    "## ToTensor()\n",
    "ToTensor将 PIL 图像或 NumPy ndarray 转换为 FloatTensor 。并在 [0., 1.] 范围内缩放图像的像素强度值\n",
    "\n",
    "## Lambda Transforms\n",
    "Lambda 转换应用任何用户定义的 lambda 函数。在这里，我们定义一个函数将整数转换为 one-hot 编码张量。它首先创建一个大小为 10 的零张量（数据集中的标签数量）并调用scatter_ ，它在标签y给定的索引上分配value=1 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1eb2a-dc24-40db-a7bf-2ef7fe3812a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
